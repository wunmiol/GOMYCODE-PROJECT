{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMiBnSH8axdYev3jJLHb2yh"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# ***A. ENCODING***"],"metadata":{"id":"JHHvWuQqalz3"}},{"cell_type":"markdown","source":["**Identify categorical columns:** This line identifies which columns in the DataFrame data are categorical. Categorical columns are those with data type object (which typically represents strings or other non-numeric types in pandas).\n","\n","\n","data.select_dtypes(include=[object]): This method selects all columns in data that have the data type object.\n",".columns: This attribute gets the names of those columns."],"metadata":{"id":"KSYJ1hiKZhvg"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"02l-LSrzVazx"},"outputs":[],"source":["# Identify categorical columns\n","categorical_cols = data.select_dtypes(include=[object]).columns\n","\n"]},{"cell_type":"markdown","source":["**Encode categorical columns using LabelEncoder:** This block of code transforms the categorical columns into numerical values.\n","label_encoders = {}: Initializes an empty dictionary to store LabelEncoder objects for each categorical column.\n","\n","\n","for col in categorical_cols:: Iterates over each categorical column identified earlier.\n","\n","\n","label_encoders[col] = LabelEncoder(): Creates a new LabelEncoder object for the current column and stores it in the dictionary label_encoders with the column name as the key.\n","\n","\n","data[col] = label_encoders[col].fit_transform(data[col]): Fits the LabelEncoder to the data in the current column (i.e., learns the mapping from original categories to integers) and transforms the column, replacing the original categorical data with the encoded numerical values."],"metadata":{"id":"vgdFhgKHZ7yl"}},{"cell_type":"code","source":["# Encode categorical columns using LabelEncoder\n","label_encoders = {}\n","for col in categorical_cols:\n","    label_encoders[col] = LabelEncoder()\n","    data[col] = label_encoders[col].fit_transform(data[col])\n","\n","# Verify encoding\n","print(data.head())"],"metadata":{"id":"V1HwYdwdZ2Tg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Techniques Used\n","Identification of Categorical Columns: Using select_dtypes to filter out columns based on their data type is a common technique in data preprocessing. It helps in isolating categorical features that need to be transformed for machine learning models.\n","\n","Label Encoding: LabelEncoder from the sklearn.preprocessing module is used to convert categorical data into numerical data. This technique assigns a unique integer to each category in the column. This is particularly useful for converting string labels into numeric form, which is required for many machine learning algorithms.\n","\n","Dictionary for Encoders: Storing each LabelEncoder in a dictionary allows easy access and potential reverse transformation (converting numerical values back to original categories) if needed later. This is a good practice for maintaining mappings, especially when dealing with multiple categorical columns.\n","\n","Transformation and Fitting: fit_transform is a method that combines fitting (learning the mapping) and transforming (applying the mapping) in one step. This is efficient and ensures that the transformation is consistent.\n","\n","By using these techniques, the code effectively prepares categorical data for machine learning by encoding it into a numerical format, making it suitable for algorithms that require numerical input."],"metadata":{"id":"ReIWmyuyakL3"}},{"cell_type":"markdown","source":["# ***B. UNDERSTANDING PREDICT_PROB***"],"metadata":{"id":"6FFWI2lSggNn"}},{"cell_type":"markdown","source":["The predict_proba method in scikit-learn is used to get the probability estimates for all classes for each sample in the input. When using a binary classifier like DecisionTreeClassifier, this method returns a 2D array where each row corresponds to a sample and each column corresponds to a class (in this case, class 0 and class 1)."],"metadata":{"id":"jhcaLLWLgmlV"}},{"cell_type":"markdown","source":["model.predict_proba(X_test):\n","\n","This part of the code uses the trained Decision Tree model to predict the probability that each sample in the test set (X_test) belongs to each class.\n","The output is a 2D array of shape (n_samples, n_classes), where n_samples is the number of samples in the test set, and n_classes is the number of classes (2 in the case of a binary classifier).\n"],"metadata":{"id":"4ck4qoW4g4fZ"}},{"cell_type":"code","source":["y_pred_proba = model.predict_proba(X_test)[:, 1]\n"],"metadata":{"id":"ZDO_KDLaajrZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **`2. Example Output:`**\n","Suppose we have a test set with 3 samples. The output might look like this:"],"metadata":{"id":"ryCqcmprhBpJ"}},{"cell_type":"code","source":["[[0.7, 0.3],\n"," [0.4, 0.6],\n"," [0.2, 0.8]]\n"],"metadata":{"id":"h8lJhyP5g27M"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Each row corresponds to a sample, and each column corresponds to a class. The first column (index 0) represents the probability of the sample belonging to class 0, and the second column (index 1) represents the probability of the sample belonging to class 1."],"metadata":{"id":"4Sq1J_cShJXc"}},{"cell_type":"markdown","source":["## **3.    [:, 1]:**\n","\n","This part of the code selects the probabilities of the positive class (class 1) for all samples.\n",": selects all rows (i.e., all samples).\n","1 selects the second column (index 1), which contains the probabilities of class 1."],"metadata":{"id":"_ZVQGE3DhQb-"}},{"cell_type":"markdown","source":["## **4. Resulting y_pred_proba:**\n","\n","The resulting y_pred_proba is a 1D array containing the probabilities of the positive class (class 1) for each sample in the test set.\n"],"metadata":{"id":"QY391wfijcQ7"}},{"cell_type":"code","source":["[0.3, 0.6, 0.8]\n"],"metadata":{"id":"lKWJW8A5hMcP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["This means:\n","The first sample has a 30% probability of belonging to class 1.\n","\n","The second sample has a 60% probability of belonging to class 1.\n","\n","The third sample has an 80% probability of belonging to class 1."],"metadata":{"id":"QfyohIZpj3IL"}},{"cell_type":"markdown","source":["### **Why Use Probabilities?**\n","Threshold Adjustment: By using probabilities, you can set different thresholds for deciding class membership. For example, instead of a fixed threshold of 0.5, you might choose a different value based on the problem's requirements.\n","\n","\n","ROC Curve and AUC: To compute the ROC curve and AUC, you need probability estimates rather than binary predictions. The ROC curve evaluates how well the model distinguishes between classes at various threshold levels.\n","Interpretability: Probabilities provide more information than binary predictions. They tell you the confidence of the model in its predictions.\n","\n","\n","Practical Use\n","When you call predict_proba, you get the probability estimates for each class for each sample. By extracting the probabilities for the positive class, you can evaluate the model's performance using metrics that require probability estimates, such as the ROC curve and AUC."],"metadata":{"id":"Gi4rdY1lkB61"}},{"cell_type":"markdown","source":["# **Example**\n","## **Here's a full example to illustrate:**"],"metadata":{"id":"UHmgaz-HkPDc"}},{"cell_type":"code","source":["from sklearn.tree import DecisionTreeClassifier\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import roc_curve, auc\n","import matplotlib.pyplot as plt\n","\n","# Example data (X and y)\n","X = [[0, 0], [1, 1], [2, 2], [3, 3]]\n","y = [0, 1, 1, 0]\n","\n","# Split the data\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)\n","\n","# Train the model\n","model = DecisionTreeClassifier(random_state=42)\n","model.fit(X_train, y_train)\n","\n","# Predict probabilities\n","y_pred_proba = model.predict_proba(X_test)[:, 1]\n","\n","# Compute ROC curve and AUC\n","fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n","roc_auc = auc(fpr, tpr)\n","\n","# Plot ROC curve\n","plt.figure()\n","plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n","plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n","plt.xlim([0.0, 1.0])\n","plt.ylim([0.0, 1.05])\n","plt.xlabel('False Positive Rate')\n","plt.ylabel('True Positive Rate')\n","plt.title('Receiver Operating Characteristic')\n","plt.legend(loc=\"lower right\")\n","plt.show()\n"],"metadata":{"id":"FMxAGkpqh-4Y"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **QUESTION**\n","# **[:, 1]**\n","# **why are we just selecting the second column**"],"metadata":{"id":"czySgFe-qP3Z"}},{"cell_type":"markdown","source":["In this example, y_pred_proba will contain the predicted probabilities for the positive class for each sample in X_test. These probabilities are then used to compute the ROC curve and AUC."],"metadata":{"id":"Dj91jQ49kjv5"}},{"cell_type":"markdown","source":["In the context of binary classification with predict_proba, the second column (index 1) represents the predicted probabilities for the positive class (class 1). Let's break down the reason why we focus on this column specifically:\n","\n","Binary Classification\n","In binary classification, there are two classes:\n","\n","Class 0 (negative class)\n","Class 1 (positive class)\n","When using predict_proba with a binary classifier, the method returns a 2D array where:\n","\n","The first column (index 0) contains the predicted probabilities for class 0 (negative class).\n","The second column (index 1) contains the predicted probabilities for class 1 (positive class).\n","Why Focus on the Second Column?\n","ROC Curve and AUC Calculation:\n","\n","The ROC curve (Receiver Operating Characteristic curve) and AUC (Area Under the Curve) are used to evaluate the performance of a binary classifier. These metrics require the predicted probabilities for the positive class (class 1).\n","By focusing on the second column (index 1), we get the probabilities that the classifier assigns to the positive class for each test sample. These probabilities are essential for computing the true positive rate (TPR) and false positive rate (FPR) at various thresholds.\n","Decision Thresholds:\n","\n","In many applications, you might want to adjust the decision threshold based on the predicted probabilities for the positive class. For example, instead of using a default threshold of 0.5, you might set a higher threshold if you want to reduce false positives or a lower threshold if you want to reduce false negatives.\n","The probabilities in the second column allow you to make such adjustments and evaluate the classifier's performance at different thresholds.\n","Interpretability:\n","\n","Probabilities for the positive class (class 1) provide a clear and interpretable measure of the classifier's confidence. For instance, a probability of 0.8 for class 1 means the classifier is 80% confident that the sample belongs to the positive class.\n","Example\n","Let's illustrate this with a simple example. Suppose we have a test set with 3 samples, and the predict_proba method returns the following probabilities:"],"metadata":{"id":"g40h2Ok3qNpl"}},{"cell_type":"code","source":["# Example output of predict_proba for 3 samples\n","proba = np.array([[0.7, 0.3],  # Sample 1: 70% probability for class 0, 30% probability for class 1\n","                  [0.4, 0.6],  # Sample 2: 40% probability for class 0, 60% probability for class 1\n","                  [0.2, 0.8]]) # Sample 3: 20% probability for class 0, 80% probability for class 1\n"],"metadata":{"id":"ZLUmGQOqkkcg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Here:\n","\n","For Sample 1, the classifier predicts a 70% probability that it belongs to class 0 and a 30% probability that it belongs to class 1.\n","\n","\n","For Sample 2, the classifier predicts a 40% probability that it belongs to class 0 and a 60% probability that it belongs to class 1.\n","\n","\n","For Sample 3, the classifier predicts a 20% probability that it belongs to class 0 and an 80% probability that it belongs to class 1.\n","\n","If we want to compute the ROC curve and AUC, we need the probabilities for class 1:"],"metadata":{"id":"sShAOodPq9mG"}},{"cell_type":"code","source":["# Extract the probabilities for the positive class (class 1)\n","y_pred_proba = proba[:, 1]\n","print(y_pred_proba)  # Output: [0.3, 0.6, 0.8]\n"],"metadata":{"id":"iARP1mnsq-Jm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **Summary**\n","\n","[:, 1] selects the probabilities for the positive class (class 1).\n","These probabilities are used to compute evaluation metrics like the ROC curve and AUC, which help assess the classifier's performance.\n","Focusing on the second column allows for better interpretability and decision-making based on the classifier's confidence in predicting the positive class."],"metadata":{"id":"prfDHmm7rHvn"}},{"cell_type":"markdown","source":["## **C. HYPERPARAMETER TUNNING**"],"metadata":{"id":"67eBASHH99a9"}},{"cell_type":"markdown","source":["**Techniques and Tools**\n","\n","1. Scikit-Learn's GridSearchCV and RandomizedSearchCV:"],"metadata":{"id":"0Xc9H-wO-MIR"}},{"cell_type":"code","source":["from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n","\n","# Define the parameter grid for grid search\n","param_grid = {\n","    'n_estimators': [100, 200, 300],\n","    'max_depth': [None, 10, 20, 30],\n","    'min_samples_split': [2, 5, 10]\n","}\n","\n","# Instantiate a grid search\n","grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='accuracy')\n","\n","# Fit the grid search\n","grid_search.fit(X_train, y_train)\n","\n","# Best hyperparameters\n","best_params = grid_search.best_params_\n"],"metadata":{"id":"coXdgpRf-GKY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["2. Hyperopt"],"metadata":{"id":"oC_mrZXo-W_l"}},{"cell_type":"code","source":["from hyperopt import hp, fmin, tpe, Trials, STATUS_OK\n","\n","# Define the search space\n","search_space = {\n","    'max_depth': hp.choice('max_depth', [10, 20, 30]),\n","    'n_estimators': hp.choice('n_estimators', [100, 200, 300]),\n","    'learning_rate': hp.uniform('learning_rate', 0.01, 0.1)\n","}\n","\n","def objective(params):\n","    model = SomeModel(**params)\n","    accuracy = cross_val_score(model, X_train, y_train, cv=5).mean()\n","    return {'loss': -accuracy, 'status': STATUS_OK}\n","\n","# Run the optimization\n","trials = Trials()\n","best_params = fmin(fn=objective, space=search_space, algo=tpe.suggest, max_evals=100, trials=trials)\n"],"metadata":{"id":"GuyCFLZk-X1l"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["3. Optuna"],"metadata":{"id":"jaYokn3S-i4A"}},{"cell_type":"code","source":["import optuna\n","\n","def objective(trial):\n","    n_estimators = trial.suggest_int('n_estimators', 100, 300)\n","    max_depth = trial.suggest_int('max_depth', 10, 30)\n","    learning_rate = trial.suggest_float('learning_rate', 0.01, 0.1)\n","    model = SomeModel(n_estimators=n_estimators, max_depth=max_depth, learning_rate=learning_rate)\n","    accuracy = cross_val_score(model, X_train, y_train, cv=5).mean()\n","    return accuracy\n","\n","study = optuna.create_study(direction='maximize')\n","study.optimize(objective, n_trials=100)\n","best_params = study.best_params\n"],"metadata":{"id":"3jnq5CUM-klM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["4. Bayesian Optimization with Scikit-Optimize:"],"metadata":{"id":"pXtjlkvj-ogO"}},{"cell_type":"code","source":["from skopt import BayesSearchCV\n","\n","# Define the search space\n","search_space = {\n","    'n_estimators': (100, 300),\n","    'max_depth': (10, 30),\n","    'learning_rate': (0.01, 0.1, 'uniform')\n","}\n","\n","# Instantiate a Bayes search\n","bayes_search = BayesSearchCV(estimator=model, search_spaces=search_space, n_iter=32, cv=5, scoring='accuracy')\n","\n","# Fit the search\n","bayes_search.fit(X_train, y_train)\n","\n","# Best hyperparameters\n","best_params = bayes_search.best_params_\n"],"metadata":{"id":"-9oVCpXm-rMJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Practical Tips\n","\n","--Start Simple: Begin with a simple grid or random search to get a sense of which hyperparameters are more influential.\n","\n","--Use Cross-Validation:\n","Always use cross-validation to ensure that your hyperparameter choices generalize well to unseen data.\n","\n","--Iterate:\n","Hyperparameter tuning is often an iterative process. Use insights from initial runs to refine your search space.\n","\n","--Balance Computational Cost:\n","Be mindful of the computational resources available and try to balance the thoroughness of the search with the computational cost.\n","\n","By applying these techniques and tools, you can effectively tune hyperparameters to achieve better performance from your machine learning models."],"metadata":{"id":"1o13ylm3-umi"}},{"cell_type":"code","source":[],"metadata":{"id":"HR4OmGDe-zhN"},"execution_count":null,"outputs":[]}]}