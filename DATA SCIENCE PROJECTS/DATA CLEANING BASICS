{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNHyc4kIdSiWjkp+mCimUOd"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Proper data cleaning is a crucial step in preparing a dataset for a machine learning problem. Clean data improves the performance of machine learning models by ensuring that the input data is accurate, complete, and consistent. Here are the steps required for proper data cleaning:\n","\n","**Steps for Proper Data Cleaning**\n","1. Understand the Data:\n","\n","Load the Data: Import the dataset using appropriate libraries (e.g., pandas for CSV files).\n","Explore the Data: Use methods like head(), describe(), info() to get an initial understanding of the data's structure, types, and basic statistics.\n","2. Handle Missing Values:\n","\n","Identify Missing Values: Use methods like isnull().sum() to check for missing values.\n","Decide on a Strategy:\n","Remove Missing Values: Drop rows or columns with missing values using dropna().\n","Impute Missing Values: Fill in missing values using statistical methods (e.g., mean, median, mode) or more complex techniques like KNN imputation.\n","3. Handle Duplicate Data:\n","\n","Identify Duplicates: Use duplicated() to find duplicate rows.\n","Remove Duplicates: Drop duplicate rows using drop_duplicates().\n","4. Handle Outliers:\n","\n","Identify Outliers: Use statistical methods (e.g., Z-score, IQR) or visual methods (e.g., box plots) to detect outliers.\n","Decide on a Strategy:\n","Remove Outliers: Exclude outliers from the dataset.\n","Transform Outliers: Apply transformations like log or square root to reduce the impact of outliers.\n","5. Standardize or Normalize Data:\n","\n","Scaling Features: Use StandardScaler for standardization (mean=0, std=1) or MinMaxScaler for normalization (scale to a range, e.g., [0, 1]).\n","6. Handle Categorical Data:\n","\n","Encoding Categorical Variables: Convert categorical data to numerical data using methods like one-hot encoding (pd.get_dummies()) or label encoding.\n","7. Feature Engineering:\n","\n","Create New Features: Generate new relevant features from the existing data.\n","Feature Selection: Select the most important features using methods like correlation analysis, feature importance from models, or dimensionality reduction techniques like PCA.\n","8. Handle Text Data (if applicable):\n","\n","Text Preprocessing: Tokenization, removing stop words, stemming, lemmatization, and vectorization (e.g., TF-IDF, word embeddings).\n","9. Ensure Consistency:\n","\n","Consistent Data Types: Ensure all columns have the appropriate data types using astype().\n","Consistent Formatting: Standardize date formats, string cases, and numerical precision.\n","10. Handle Time-Series Data (if applicable):\n","\n","Resampling: Aggregate data to a different time frequency if needed.\n","Dealing with Seasonality and Trends: Use techniques like differencing or seasonal decomposition."],"metadata":{"id":"Awu7l0itzLlj"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Dt9CVwuXzA8s"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.preprocessing import StandardScaler, OneHotEncoder\n","from sklearn.impute import SimpleImputer\n","\n","# Load the data\n","df = pd.read_csv('data.csv')\n","\n","# Explore the data\n","print(df.head())\n","print(df.describe())\n","print(df.info())\n","\n","# Handle missing values\n","imputer = SimpleImputer(strategy='mean')  # Example strategy\n","df[['numeric_column']] = imputer.fit_transform(df[['numeric_column']])\n","\n","# Handle duplicate data\n","df = df.drop_duplicates()\n","\n","# Handle outliers (example using IQR)\n","Q1 = df['numeric_column'].quantile(0.25)\n","Q3 = df['numeric_column'].quantile(0.75)\n","IQR = Q3 - Q1\n","df = df[~((df['numeric_column'] < (Q1 - 1.5 * IQR)) | (df['numeric_column'] > (Q3 + 1.5 * IQR)))]\n","\n","# Standardize or normalize data\n","scaler = StandardScaler()\n","df[['numeric_column']] = scaler.fit_transform(df[['numeric_column']])\n","\n","# Handle categorical data\n","encoder = OneHotEncoder()\n","encoded_features = encoder.fit_transform(df[['categorical_column']]).toarray()\n","df = df.drop('categorical_column', axis=1)\n","df = pd.concat([df, pd.DataFrame(encoded_features)], axis=1)\n","\n","# Feature engineering (example)\n","df['new_feature'] = df['existing_feature1'] * df['existing_feature2']\n","\n","# Ensure consistency\n","df['date_column'] = pd.to_datetime(df['date_column'])\n","df['numeric_column'] = df['numeric_column'].astype(float)\n","\n","# Example for time-series data\n","df.set_index('date_column', inplace=True)\n","df = df.resample('M').mean()  # Resample to monthly frequency\n","\n","print(df.head())\n"]}]}